---
title: "Final Assignment"
author: "Emma Pérez & Andrés Camargo"
date: "2023-05-27"
output: html_document
---

```{r setup,  warning=FALSE, message=FALSE, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Libraries

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(igraph)
library(visNetwork)
library(ggplot2)
library(ggthemes)
library(caret)
set.seed(123)

```


## 0. Network 

*LastFM Asia Social Network*

We will continue working with the social network of LastFM Asian users, which is available at the [Stanford Network Analysis Platform (SNAP)](https://snap.stanford.edu/index.html). Last.fm is a social media, an internet radio, and also a music recommendation system that builds profiles and statistics about musical preferences, based on data sent by registered users.

According to SNAP, the data was collected from the public API in March 2020. Nodes are LastFM users from Asian countries and edges are mutual follower relationships between them. The vertex features are extracted based on the artists liked by the users. It can be downloaded in csv format from [LastFM Asia Social Network](https://snap.stanford.edu/data/feather-lastfm-social.html). 

To start with, the data is loaded to R. 

```{r}
fm = read_delim("lasftm_asia/lastfm_asia_edges.csv", delim=",")
g = graph.data.frame(fm, directed = FALSE)
```

## a) Epidemic threshold

*Find the theoretical epidemic threshold βc for your network for the information to reach a significant number of nodes.*

```{r}
mu <- 0.1
betac <- mu*mean(degree(g))/(mean(degree(g)^2))
betac
```
The parameter "mu" represents the recovery rate, indicating the rate at which infected individuals recover and acquire immunity to the disease. The epidemic threshold is defined as the minimum value of the transmission rate "beta" required for an epidemic to initiate and persist within a population.

Assuming $mu = 0.1$, the epidemic threshold in our network is very small $(0.0039)$, because of the heterogeneity in the degree distribution $(⟨k⟩ = 7.3$ and $⟨k^2⟩ = 185.4$, so $⟨k^2⟩>>⟨k⟩)$. Therefore,as the epidemic threshold βc is really small, it is very easy to spread in this network!


## b) SIR simulation

*Assuming that randomly-selected 1% of the nodes of your network knows about the information, simulate the SIR model below and above that threshold and plot the number of infected people as a function of β.*

First, we create the function for the SIR simulation, which includes parameters for the network (g), the transmission rate (beta), the recovery rate (mu), and the initial number of infected individuals (seeds).

```{r}
sim_sir <- function(g,beta,mu,seeds){
  state <- rep(0,vcount(g)) #initial state of the simulation
  state[seeds] <- 1 #infect the seeds
  t <- 0
  table <- data.frame(t=0,inf=seeds)
  while(sum(state==1)>0){
    t <- t + 1
    #I -> R
    infected <- which(state==1)
    state[infected] <- ifelse(runif(length(infected)) < mu,2,1)
    
    #S -> I
    infected <- which(state==1)
    susceptible <- which(state==0) #get them
    contacts <- as.numeric(unlist(adjacent_vertices(g,infected))) #get the contacts of infected
    contacts <- contacts[contacts %in% susceptible]
    new_infected <- contacts[runif(length(contacts)) < beta] #infect contacts
    if(length(new_infected)>0){
      state[new_infected] <- 1
      table <- rbind(table,data.frame(t,inf=new_infected))
    }
  }
  table
}
```


Now, we set the seeds to be 1% randomly chosen nodes, and set the beta value to be between 0 and 0.25 by 0.005. The value of "mu" is fixed to 0.1 as before. 

```{r}
results <- map_dfr(seq(0,0.25,0.005),
        \(beta){ seeds <- sample(1:vcount(g),vcount(g)*0.01)
        realization <- sim_sir(g,beta,mu,seeds)
        data.frame(beta,ninf=nrow(realization))
        })
results %>% ggplot(aes(x=beta,y=ninf))+ geom_point()+
  geom_vline(xintercept = betac,linetype=2)
```



## c) Acelerate Spreading

*Choose a β above βc. Using centrality, communities or any other metric, find a better set of 1% of seeds in the network so we get more infected people than the random case. Measure the difference of your choice with the random case as: *
- *The difference in the total number of infected people*
- *The difference in the time of the peak of infection (when most infections happen). * 

First, we generate the realization with a β above βc, to then check which metrics are the most correlated with the time of infection. 

```{r}
seeds <- sample(1:vcount(g),vcount(g)*0.01)
realization <- sim_sir(g,beta=0.2,mu=0.1,seeds)

```

```{r}
# Node degree
table_d <- degree(g) %>% enframe(name = "inf",value="degree") %>%
  merge(realization) 

table_d %>% 
  ggplot(aes(x=t,y=degree)) + geom_point() + scale_y_log10()
```

```{r}
# Closeness
table_c <- closeness(g,cutoff=2) %>% enframe(name = "inf",value="closeness") %>%
  merge(realization) 
table_c %>% 
  ggplot(aes(x=t,y=closeness)) + geom_point() + scale_y_log10()
```

```{r}
# Betweenness 
table_b <- betweenness(g) %>% enframe(name = "inf",value="betweenness") %>%
  merge(realization) 
table_b %>% 
  ggplot(aes(x=t,y=betweenness)) + geom_point() + scale_y_log10()
```

```{r}
# Page Rank
table_pr <- page_rank(g)$vector %>% enframe(name = "inf",value="page_rank") %>%
  merge(realization) 
table_pr %>% 
  ggplot(aes(x=t,y=page_rank)) + geom_point() + scale_y_log10()
```

Let's see which one best predict the time to infection: 

```{r}
table <- merge(table_d,table_c)
table <- merge(table,table_pr)
table <- merge(table,table_b)
cor(table$t,table[,-c(1,2)])
```
Page Rank seems to be the best

Now, we can compare the realizations with the random seeds and with the seeds selected by higher page rank.

```{r}
#Random realization
seeds <- sample(1:vcount(g),vcount(g)*0.01)#1% random seed

realization_random <- sim_sir(g,beta = 0.15,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

#Targeted nodes realization
seeds <- page_rank(g)$vector %>% enframe(name = "inf",value="page_rank") %>%
  slice_max(page_rank,n=round(vcount(g)*0.01))#1% seeds of highest page rank

realization_targeted <- sim_sir(g,beta = 0.15,mu=0.1, as.vector(as.integer(seeds$inf))) %>%
  group_by(t) %>% summarize(ninf=n())

#Graph for comparison 
ggplot() + geom_line(data=realization_random,aes(x=t,y=ninf,col="Random"))+
  geom_line(data=realization_targeted,aes(x=t,y=ninf,col="Targeted"))
```

We observe that by infecting nodes with higher centrality first, the peak of infection is reached earlier in time, and the total number of infected nodes is higher compared to random spreading. Therefore, selecting the initial seeds based on centrality metrics does accelerate the spread of the infection.

```{r}
#Random realization
seeds <- sample(1:vcount(g),vcount(g)*0.01)#1% random seed

realization_random <- sim_sir(g,beta = 0.15,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

#Targeted nodes realization
seeds <- betweenness(g) %>% enframe(name = "inf",value="betweenness") %>%
  slice_max(betweenness,n=round(vcount(g)*0.01))#1% seeds of highest page rank

realization_targeted <- sim_sir(g,beta = 0.15,mu=0.1, as.vector(as.integer(seeds$inf))) %>%
  group_by(t) %>% summarize(ninf=n())

#Graph for comparison 
ggplot() + geom_line(data=realization_random,aes(x=t,y=ninf,col="Random"))+
  geom_line(data=realization_targeted,aes(x=t,y=ninf,col="Targeted"))
```


We obtain the same result when trying with betweenness metric. 

Therefore, if we want the information to spread faster we should target the nodes with larger centrality.

## d) Inmunization

*Suppose now that you can convince 5% of people in the network not to spread that information at all:*

- *Choose those 5% randomly in the network. Simulate the SIR model above βc using 1% of the remaining nodes as seeds. Choose those seeds randomly.*
- *Choose those 5% according to their centrality. Simulate the SIR model above βc using 1% of the remaining nodes as seeds. Choose those seeds randomly.* 
- *Measure the difference between both cases as you did in part c).*

First, we simulate the SIR model using a random 5% of people: 
```{r}
seeds <- sample(1:vcount(g),vcount(g)*0.01)
realization <- sim_sir(g,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())
vaccinated_random <- sample(1:vcount(g),vcount(g)*0.05)#5% randomly chosen
gp <- delete_vertices(g,vaccinated_random)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_random <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())
```

Then, we run the simulation with the 5% chosen according to their centrality (those nodes with largest page rank)

```{r}
seeds <- page_rank(g)$vector %>% enframe(name = "inf",value="page_rank") %>%
  slice_max(page_rank,n=round(vcount(g)*0.05))#5% according to page_rank 
gp <- delete_vertices(g,seeds$inf)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_targeted <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())
```

Let's see the difference between both cases: 

```{r}
ggplot() + geom_line(data=realization,aes(x=t,y=ninf,col="No Vaccination")) +
  geom_line(data=realization_random,aes(x=t,y=ninf,col="Vacc. Random"))+
  geom_line(data=realization_targeted,aes(x=t,y=ninf,col="Vacc. Targeted"))
```

Random vaccination has a similar effect to no vaccination at all in terms of the timing of the infection peak. However, the number of infected nodes at the peak is higher without any vaccination compared to random vaccination. Due to the high heterogeneity in our network, a significant number of nodes would need to be randomly vaccinated to effectively control the spread.

In contrast, targeted vaccination based on the PageRank centrality measure reduces the number of infected individuals by more than half (from 4000 to 1500). Furthermore, the peak of infected individuals is reached later in time (at time 5 instead of time 2.5) with targeted vaccination.


## e) Analysis of Inmunization

*Comment on the relationship between the findings in part c) and d) using the same type of centrality for the 1% in part c) and 5% in part d).*

According to the graphs obtained in parts (c) and (d), selecting the initial seeds based on higher PageRank leads to accelerated spreading (c). Similarly, when targeting immunization using PageRank, it delays the peak of spreading (d). This occurs because we have identified nodes in the network that possess greater influence on the spread of the behavior. The impact generated by nodes with higher centrality is manifested in the propagation throughout the network, initiating cascades of influence that result in a greater spread of the behavior in case (c) or reduced spreading in case (d).

## f) Influence Maximization

*With the results of part b) train a model that predicts that time to infection of a node using their degree, centrality, betweeness and page rank. Use that model to select the seed nodes as those with the smallest time to infection in part c).*

To develop a predictive model for node infection time using degree, centrality, betweenness, and PageRank, we employed a multiclass classification approach. The target variable was created by categorizing nodes into four infection time categories: "very fast" (time < 4), "fast" (5-8), "medium" (9-12), and "slow" (> 12). A comprehensive dataset was compiled, including the relevant characteristics for each node. Subsequently, the dataset was divided into separate train and test subsets to evaluate the model's performance. For the classification task, we chose the random forest algorithm.Additionally, we implemented some future engineering transformations to enhance the predictive power of our model. Finally, we conducted an evaluation of the model to assess its predictive capabilities and effectiveness.

```{r}
# create dataframe 
seeds <- sample(1:vcount(g),vcount(g)*0.01)
realization <- sim_sir(g,beta=0.2,mu=0.1,seeds) 
realization = realization %>% distinct()

nodes_data <- data.frame(
  id = as.numeric(V(g)$name),
  degree = degree(g),  
  closeness = closeness(g,cutoff=2),  
  betweenness = betweenness(g),  
  pageRank = page.rank(g)$vector  
) 

hist(realization$t)
nodes_df = nodes_data %>% left_join(realization, by= c('id'='inf')) %>% 
  drop_na() %>% 
  mutate(
    category = as.factor(case_when(
      t <= 4 ~ "Very Fast",
      t > 4 & t <= 8 ~ "Fast",
      t > 8 & t <= 12 ~ "Medium",
      t > 12 ~ "Slow"
  ))) %>% 
  filter(t != 0)


head(nodes_df)
``` 


```{r}
# model for multiclass classification
in_train <- createDataPartition(nodes_df$category, p = 0.75, list = FALSE)  
training <- nodes_df[in_train,]
testing <- nodes_df[-in_train,]

# Cross-validation method
ctrl <- trainControl(method = "cv",   
                     number = 5,      
                     verboseIter = FALSE)

# Train a Random Forest classifier with cross-validation
model <- train(category ~ degree + closeness + betweenness + pageRank + closeness* betweenness + betweenness * pageRank + degree^2 + pageRank^2,
          data = training,
          method = "rf",            
          trControl = ctrl)         

# Print the model results
print(model)

# Make predictions on new data using the trained model
predictions <- predict(model, testing)
confusionMatrix(predictions, testing$category)
```


```{r}
randomForest::varImpPlot(model$finalModel)
```

The graph depicting the variable importance of the random forest model offers valuable insights into the relative significance of different variables in determining the time of infection for a node. Among the variables considered, PageRank stands out as the most influential factor. This highlights that the ranking of nodes based on their importance within the network plays a substantial role in determining the timing of infection. Following PageRank, closeness emerges as the second most important variable. This suggests that nodes with higher closeness centrality, indicating closer connections to other nodes in the network, tend to exhibit distinct patterns in terms of infection timing. This finding underscores the impact of proximity and immediate network connections on the spread of infection.

In the spectrum of variable importance, interactions between variables occupy a medium position. These interactions reflect the combined influence of multiple factors and their interplay in shaping the timing of infection. Considering these interactions can provide a deeper understanding of the complexities involved in predicting infection times accurately. On the other hand, degree appears to be the least important variable among the four considered. This implies that the number of connections a node has in the network has a relatively smaller impact on the timing of infection. Nonetheless, it still contributes to the model's predictions, albeit to a lesser extent compared to the other variables.

Thus, first we generate the prediction for all nodes in the network, to then select those with the shortest time to infection:
```{r}
#Predicting time to infection for all nodes
nodes_df <- nodes_df %>% mutate(time_pred = predict(model, nodes_df))
seeds <- nodes_df %>% slice_min(time_pred, n = round(vcount(g)*0.01)) %>% pull(id)
head(seeds)
```

## Repeat c). 

```{r}
#Random realization
seeds <- sample(1:vcount(g),vcount(g)*0.01)#1% random seed

realization_random <- sim_sir(g,beta = 0.15,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

#Targeted nodes realization
seeds <- nodes_df %>% filter(time_pred == "Very Fast") %>% pull(id)
seeds <- sample(seeds, round(vcount(g)*0.01))
realization_targeted <- sim_sir(g,beta = 0.15,mu=0.1, seeds) %>%
  group_by(t) %>% summarize(ninf=n())

#Graph for comparison 
ggplot() + geom_line(data=realization_random,aes(x=t,y=ninf,col="Random"))+
  geom_line(data=realization_targeted,aes(x=t,y=ninf,col="Targeted"))
```
We can see again that using as seeds the nodes with the shortest predicted time to infection, we maximize the spread, since the number of infected nodes is higher in the peak. 


## Repeat d).

First, we generate a SIR model with randomly selected nodes.

```{r}
#No vaccination 
seeds <- sample(1:vcount(g),vcount(g)*0.01)
realization <- sim_sir(g,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

#Random vaccination
vaccinated_random <- sample(1:vcount(g),vcount(g)*0.05)#5% randomly chosen
gp <- delete_vertices(g,vaccinated_random)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_random <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())
```

Then, we run the simulation with the 5% chosen according to our model.

```{r}
# Target vaccination 
seeds <- nodes_df %>% slice_min(time_pred, n = round(vcount(g)*0.05)) %>% pull(id)#5% nodes to vaccinate
gp <- delete_vertices(g,seeds)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_modelselected <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())
```

Let's see the difference between both cases: 

```{r}
ggplot() + geom_line(data=realization,aes(x=t,y=ninf,col="No Vaccination")) +
  geom_line(data=realization_random,aes(x=t,y=ninf,col="Vacc. Random"))+
  geom_line(data=realization_modelselected,aes(x=t,y=ninf,col="Vacc. Selected by model"))
```

The application of the influence maximization model, incorporating centrality metrics, led to the development of a targeted vaccination strategy. This strategic approach resulted in a significant reduction in the number of infected individuals, demonstrating its effectiveness compared to random vaccination methods. It is important to note, however, that despite the success in reducing the number of infections, the model did not have a noticeable impact on the overall duration of the spreading process. While the targeted vaccination strategy efficiently identified and prioritized influential nodes for vaccination, it did not directly influence the rate at which the infection spread through the network.



## APPENDIX 

In addition to the model previously explained, we created alternative models that were discarded due to their low performance for influence maximization. The first alternative is a classification model that identifies high and low central nodes using its metrics. The second one is a linear regression that uses the time of spreading as a continuous target variable. The code is provided below but has not been executed.

##### Model Option 2 (node classification according to percentiles)

```
# create dataframe of predictors
nodes_data <- data.frame(
  id = as.numeric(V(g)$name),
  degree = degree(g),  
  closeness = closeness(g,cutoff=2),  
  betweenness = betweenness(g),  
  pageRank = page.rank(g)$vector  
) 

# create target variable
nodes_df = nodes_data %>%  
  mutate(
    category = as.factor(case_when(
      degree >= quantile(degree, probs = 0.95) |
      closeness >= quantile(closeness, probs = 0.9) |
      pageRank >= quantile(pageRank, probs = 0.9) |
      betweenness >= quantile(betweenness, probs = 0.9) ~ "High",
    TRUE ~ "Low"))) 

table(nodes_df$category)
head(nodes_df)

# Train
model <- train(category ~ degree + closeness + betweenness + pageRank,
          data = nodes_df,
          method = "rf",            
          trControl = ctrl)  
# Predict
nodes_df <- nodes_df %>% mutate(time_pred = predict(model))


# Compare SIR realizations
seeds <- sample(1:vcount(g),vcount(g)*0.01)
realization <- sim_sir(g,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

vaccinated_random <- sample(1:vcount(g),vcount(g)*0.05)#5% randomly chosen
gp <- delete_vertices(g,vaccinated_random)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_random <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())


seeds <- nodes_df %>% filter(time_pred == "High") %>% pull(id)
sample_seeds <- sample(seeds, round(vcount(g)*0.05))
gp <- delete_vertices(g,seeds)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_modelselected <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

ggplot() + geom_line(data=realization,aes(x=t,y=ninf,col="No Vaccination")) +
  geom_line(data=realization_random,aes(x=t,y=ninf,col="Vacc. Random"))+
  geom_line(data=realization_modelselected,aes(x=t,y=ninf,col="Vacc. Selected by model"))
  
``` 

```
#Random realization
seeds <- sample(1:vcount(g),vcount(g)*0.01)#1% random seed

realization_random <- sim_sir(g,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

#Targeted nodes realization
seeds <- nodes_df %>% filter(time_pred == "High") %>% pull(id)
seeds <- sample(seeds, round(vcount(g)*0.01))
realization_targeted <- sim_sir(g,beta = 0.5,mu=0.1, seeds) %>%
  group_by(t) %>% summarize(ninf=n())

#Graph for comparison 
ggplot() + geom_line(data=realization_random,aes(x=t,y=ninf,col="Random"))+
  geom_line(data=realization_targeted,aes(x=t,y=ninf,col="Targeted"))
```


##### Model Option 3 (target variable as continuous)

```
seeds <- sample(1:vcount(g),vcount(g)*0.01)
realization <- sim_sir(g,beta=0.5,mu=0.1,seeds) 
realization = realization %>% distinct()

nodes_data <- data.frame(
  id = as.numeric(V(g)$name),
  degree = degree(g),  
  closeness = closeness(g,cutoff=2),  
  betweenness = betweenness(g),  
  pageRank = page.rank(g)$vector  
) 

nodes_df = nodes_data %>% left_join(realization, by= c('id'='inf')) %>% 
  drop_na() 

head(nodes_df)

# Fit model and predict
model <- lm(t ~ degree + closeness + betweenness + pageRank + closeness* betweenness + betweenness * pageRank + degree^2 + pageRank^2)
pred = predict(model)
nodes_df <- nodes_df %>% mutate(time_pred = predict(model))

# compare SIR realizations
#No vaccination
seeds <- sample(1:vcount(g),vcount(g)*0.01)
realization <- sim_sir(g,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

#Random vaccination
vaccinated_random <- sample(1:vcount(g),vcount(g)*0.05)#5% randomly chosen
gp <- delete_vertices(g,vaccinated_random)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_random <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

#Target vaccionation
seeds <- nodes_df %>% slice_min(time_pred, n = round(vcount(g)*0.05)) %>% pull(id)
gp <- delete_vertices(g,seeds)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_modelselected <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

ggplot() + geom_line(data=realization,aes(x=t,y=ninf,col="No Vaccination")) +
  geom_line(data=realization_random,aes(x=t,y=ninf,col="Vacc. Random"))+
  geom_line(data=realization_modelselected,aes(x=t,y=ninf,col="Vacc. Selected by model"))
```


##### Model 4. Poisson

```
in_train <- createDataPartition(nodes_df$t, p = 0.75, list = FALSE)  
training <- nodes_df[in_train,]
testing <- nodes_df[-in_train,]

# Cross-validation method
ctrl <- trainControl(method = "repeatedcv",   
                     number = 5,      
                     verboseIter = FALSE)

# Train a Random Forest classifier with cross-validation
model <- train(t ~ degree + closeness + betweenness + pageRank + closeness* betweenness + betweenness * pageRank + degree^2 + pageRank^2,
          data = training,
          preProcess = c("scale", "center"),
          method = "rf",  
          trControl = ctrl)   

pred = predict(model, testing)

nodes_df <- nodes_df %>% mutate(time_pred = predict(model, nodes_df))
head(nodes_df)

# First, we simulate the SIR model using a random 5% of people 

seeds <- sample(1:vcount(g),vcount(g)*0.01)
realization <- sim_sir(g,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

vaccinated_random <- nodes_df %>% slice_min(time_pred, n = round(vcount(g)*0.05)) %>% pull(id) #5% randomly chosen
gp <- delete_vertices(g,vaccinated_random)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_random <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

# Then, we run the simulation with the 5% chosen according to their centrality (those nodes with largest page rank)
seeds <- nodes_df %>% slice_min(time_pred, n = round(vcount(g)*0.05))#5% according to page_rank 
gp <- delete_vertices(g,seeds$id)
seeds <- sample(1:vcount(gp),vcount(gp)*0.01)
realization_targeted <- sim_sir(gp,beta = 0.5,mu=0.1,seeds) %>%
  group_by(t) %>% summarize(ninf=n())

# Let's see the difference between both cases: 
ggplot() + geom_line(data=realization,aes(x=t,y=ninf,col="No Vaccination")) +
  geom_line(data=realization_random,aes(x=t,y=ninf,col="Vacc. Random"))+
  geom_line(data=realization_targeted,aes(x=t,y=ninf,col="Vacc. Targeted"))

```







